	\documentclass[twoside]{article}
\usepackage{../../estilo-ejercicios}

%--------------------------------------------------------
\begin{document}

\title{Ejercicios de From Calculus to Cohomology, Capítulo 9}
\author{Javier Aguilar Martín}
\maketitle

\begin{ejercicio}{9.1}
Sea $M\subseteq\R^l$ una subvariedad diferenciable y supongamos que los puntos $p\in\R^l$ y $p_0\in M$ son tales que $||p-p_0||\leq ||p-q||$ para todo $q\in M$. Probar que $p-p_0\in T_{p_0}M^{\perp}$.
\end{ejercicio}
\begin{solucion}
Podemos considerar $T_{p_0}M$ como subespacio de $\R^l$, por lo que el resultado se deduce del teorema de la proyección. 
%https://math.stackexchange.com/questions/1492497/projection-theorem-understanding-two-parts-of-the-proof
\end{solucion}
\newpage


\begin{ejercicio}{9.9}
En el espacio vectorial $M=M_n(\R)$ de matrices reales $n\times n$ tenemos el subespacio de matrices simétricas $S_n$. Definimos la aplicación diferenciable $\varphi:M\to S_n$ como 
\[
\varphi(A)=A^tA.
\]
Nótese que $\varphi^{-1}(I)$ es el espacio de matrices ortogonales $O_n$. Probar que para $A,B\in M$ tenemos
\[
D_A\varphi(B)=B^tA+A^tB.
\]
(Pista: usar la curva $A+sB$)
Aplicar el ejercicio 9.6 para probar que $O_n$ es una subvariedad diferenciable de $M$.
\end{ejercicio}
\begin{solucion}
Tomamos la curva $\gamma(s)=A+sB$ tal que $\gamma'(0)=B$. Entonces, 
\[
D_A\varphi(B)=D_A\varphi(\gamma'(0))=(\varphi\circ\gamma)'(0)=A^tB+B^tA.
\]

Para la segunda parte tenemos que probar que $D_A\varphi$ es sobreyectiva para toda matriz ortogonal $A$. Es decir, dada $\gamma:[0,1]\to S_n$ con $\gamma'(0)\in S_n$, tenemos que encontrar $B\in M$ tal que $\gamma'(0)=B^tA+A^tB$. Para ello hacemos la siguiente descomposición:
\[
\gamma'(0)=\frac{(\gamma'(0)A^t)}{2}A+A^t\frac{(A\gamma'(0))}{2}
\]
con lo que $B=\frac{A\gamma'(0)}{2}$.
\end{solucion}
\newpage

\begin{ejercicio}{9.10}
Un \emph{grupo de Lie} $G$ es una variedad diferenciable, que es también un grupo, tal que el producto y tomar inverso son diferenciables. Demostrar que $O_n$ es un grupo de Lie. (Aplicar \ref{ejer:9.9})
\end{ejercicio}
\begin{solucion}
$O_n$ hereda la estructura diferenciable de $M_n(\R)$, que es equivalente a la de $\R^{n\times n}$. Es claro que el producto de matrices es diferenciable, luego en $O_n$ lo es. En el caso de la inversa, como en el caso de $O_n$ es igual a trasponer, que no es más que una reordenación de las coordenadas es también claro que se trata de una aplicación diferenciable.
\end{solucion}
\newpage

\begin{ejercicio}{9.11}
Sea $\varphi:M\to N$ una aplicación diferenciable entre variedades diferenciables. Probar que $\varphi^*:\Omega^*(N)\to\Omega^*(M)$ es un morfismo de complejos de cadenas.
\end{ejercicio}
\begin{solucion}
Tenemos que probar que el siguiente diagrama es conmutativo 
\[
\begin{tikzcd}
\Omega^k(N)\arrow[r,"d^k"]\arrow[d,"\varphi^*"] & \Omega^{k+1}(N)\arrow[d,"\varphi^*"]\\
\Omega^k(M)\arrow[r, "d^k"] & \Omega^{k+1}(M)
\end{tikzcd}
\]
para todo $k$. Sea $w\in\Omega^k(N)$. Elegimos $p\in M,q=\varphi(p)\in N$ y parametrizaciones locales $g:W\to M$ y $h:V\to N$. Tenemos por definición
\[
d_qw=Alt^{k+1}((D_yh)^{-1})d_y(h^*(w))=Alt^{k+1}(D_qh^{-1})d_y(h^*(w))
\]
donde $y$ cumple $h(y)=q=\varphi(p)$, así que
\[
\varphi^*(d_qw)_p=Alt^{k+1}(D_p\varphi)\circ Alt^{k+1}(D_qh^{-1})(d_yh^*(w))=
\]
\[
Alt^{k+1}(D_qh^{-1}D_p\varphi)(d_yh^*(w))=Alt^{k+1}(D_ph^{-1}\varphi)(d_y(h^*(w)))=
\]
%\[
%Alt^{k+1}(D_ph^{-1}\varphi)(d_yAlt^k(D_yh)(w_{h(y)})).
%\]
%Ahora, por la conmutatividad de $d$ con $\Omega^k(h)$ a nivel de complejo de cocadenas de abiertos euclídeos, esto es igual a 
%\[
%Alt^{k+1}(D_ph^{-1}\varphi)Alt^{k+1}(D_yh)(d_q w_{\varphi(p)})=Alt^{k+1}(D_p\varphi)(d_yw_{\varphi(p)}).
%\]
% 
Por otro lado, 
%\[
%\varphi^*(w)_p=Alt^k(D_p\varphi)(w_{\varphi(p)}),
%\]
%así que 
eligiendo $x$ con  $g(x)=p$ tenemos
\[
d_p\varphi^*(w)=Alt^{k+1}((D_xg)^{-1})d_x(g^*(\varphi^*(w)))=
\]
%\[
%Alt^{k+1}(D_xg^{-1})d_x(Alt^k(D_xg)\circ Alt^k(D_p\varphi)(w_{\varphi(p)}))=
%\]
%\[
%Alt^{k+1}(D_xg^{-1})d_x(Alt^k(D_x\varphi g)(w_{\varphi(p)})=Alt^{k+1}(D_p\varphi)(d_x w_{\varphi(p)})
%\]

SUPONGO QUE NO ME QUEDA MÁS REMEDIO QUE EVALUAR EN VECTORES
\end{solucion}

\newpage

\begin{ejercicio}{9.12}
El producto escalar usual en $\R^n$ induce un producto escalar en $Alt^n(\R^n)$ (ver ejercicio 2.5). Probar que $w\in Alt^n(\R^n)$ es un vector unitario si y solo si $w(v_1,\dots, v_n)=\pm 1$ para toda base ortonormal $\{v_1,\dots, v_n\}$ de $\R^n$.
\end{ejercicio}
\begin{solucion}
Dada $w\in Alt^n(\R^n)$ tenemos que $w=\lambda \varepsilon_1\land\dots\varepsilon_n=\lambda\varepsilon_I$ con $\lambda\in\R$. Entonces $\gene{w,w}=\lambda^2\det(\gene{\varepsilon_i,\varepsilon_j})=\lambda^2\det(\gene{i^{-1}(\varepsilon_i),i^{-1}(\varepsilon_j)})=\lambda^2$. La última igualdad se tiene porque $i$ lleva bases ortonormales en bases ortonormales y estamos tomando la dual de la base estándar. Por otra parte, $w(v_1,\dots, v_n)=\lambda\det(\varepsilon_i(v_j))=\pm\lambda$. Así que $\gene{w,w}=1\Leftrightarrow \lambda=1\Leftrightarrow w(v_1,\dots, v_n)=\pm 1$.
\end{solucion}

\newpage

\begin{ejercicio}{9.13}
Probar que la botella de Klein no es orientable.
\end{ejercicio}
\begin{solucion}
\end{solucion}
\newpage

\begin{ejercicio}{9.15}
\end{ejercicio}
\begin{solucion}
\end{solucion}
\newpage

\begin{ejercicio}{9.16}
\end{ejercicio}
\begin{solucion}
\end{solucion}
\newpage

\begin{ejercicio}{9.17}
\end{ejercicio}
\begin{solucion}
\end{solucion}
\newpage

\begin{ejercicio}{9.18}
\end{ejercicio}
\begin{solucion}
\end{solucion}
\end{document}