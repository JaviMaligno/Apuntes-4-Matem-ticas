\documentclass[CV.tex]{subfiles}

\begin{document}


%\hyphenation{equi-va-len-cia}\hyphenation{pro-pie-dad}\hyphenation{res-pec-ti-va-men-te}\hyphenation{sub-es-pa-cio}

\chapter{Cohomología de deRham sobre abiertos euclídeos}
\section{Definiciones}
Sea $U\subseteq\R^n$ un abierto euclídeo y $\R^n$ con la base canónica $\{e_1,\dots, e_n\}$, que induce una base dual sobre $Alt^1(\R)$, $\{\varepsilon_1,\dots, \varepsilon_n\}$. Ocasionalmente se usará la notación $\varepsilon_I=\varepsilon_{i_1}\land\dots\land\varepsilon_{i_p}$, donde $I=\{1\leq i_1<\cdots<i_p\leq n\}$.

\begin{defi}
Una \textbf{$p$-forma diferenciable} sobre $U$ es 
\[
w:U\to Alt^p(\R^n)
\]
\[
x\mapsto w_x
\]
que es aplicación diferenciable $w_x(v_1,\dots, v_p)$ o también denotado $w(x)(v_1,\dots, v_p)$. 
\end{defi}

\begin{observaciones}
$w_x=\sum_{\sigma\in S(p,n-p)}(w_x)_{\sigma}\varepsilon_{\sigma}$. Por otro lado, tiene sentido hablar de diferenciabilidad pues $Alt^p(\R^n)\cong \R^{\binom{n}{p}}$, por lo que la diferenciabilidad se tendrá coordenada a coordenada. Es decir, cada $x\mapsto (w_x)_{\sigma}$ es diferenciable. 
\end{observaciones}

\begin{lemma}
El conjunto de todas las $p$-formas diferenciables $\Omega^p(U)$ es un $\R$-e.v.
\end{lemma}

Como $w$ es diferenciable, podemos considerar su derivada, $Dw$, tal que para cada $x\in U$, $D_xw:\R^n\to Alt^p(\R^n)$ es una aplicación lineal. Tendríamos entonces para cada $i=1,\dots, n$
\[
D_xw(e_i)=\frac{d}{dt}(w(x+te_i))|_{t=0}=\frac{\partial w}{\partial x_i}(x)
\]
Obsérvese que es el resultado es un vector, pues es una matriz aplicada sobre un vector. Podemos decir que $w=\sum_{\sigma}w_{\sigma}\varepsilon_{\sigma}$, donde $w_{\sigma}$ son $C^{\infty}$ diferenciables como funciones $w_{\sigma}: U\to \R=Alt^0(\R^n)$, por lo que $w_{\sigma}\in\Omega^0(U)=C^{\infty}(U;\R)$. Entonces, para cada $i=1,\dots, n$,
\[
D_xw(e_i)=\sum_{\sigma}\frac{\partial w_{\sigma}}{\partial x_i}(x)\varepsilon_{\sigma}
\]
\newpage
Así, pues
\[
Dw: U\longrightarrow \{\text{aplicaciones lineales } \R^n\to Alt^p(\R^n)\}\subseteq M_{n\times\binom{n}{p}}
\]
\[x\longmapsto D_xw:\R^n\to Alt^p(\R^n)
\]
Se tiene además que si $w\in\Omega^p(U)$ y $f\in\Omega^0(U)$, $fw\in\Omega^p(U)$, que es equivalente a decir que $(fw)_x\in Alt^p(\R^n)$, definida como $fw(x)(v_1,\dots, v_p)=f(x)w_x(v_1,\dots, v_p)$ (o sin los $v_i$). Por tanto. $\Omega^p(U)$ es un $C^{\infty}(U;\R)$-módulo. 

\begin{defi}
Definimos la \textbf{diferencial exterior}
\[
\Omega^p(U)\overset{d}{\longrightarrow} \Omega^{p+1}(U)
\]
como un homomorfismo de $\R$-e.v. $w\longmapsto dw:U\to Alt^{p+1}(\R^n)$, donde $x\mapsto d_xw:\R^n\underbrace{\times\dots \times}_{p+1}\R^n\to \R$ está definida como
\[
d_xw(v_1,\dots, v_{p+1})=\sum_{l=1}^{p+1}(-1)^{l-1}D_xw(v_l)(v_1,\dots, \hat{v}_l,\dots, v_{p+1})
\]
\end{defi}
Es fácil comprobar que $d_xw$ está bien definida. Además es multilineal por ser combinación lineal de multilineales. Probemos que es alternado. Por el lema \ref{alternado} basta comprobar que $d_xw(v_1,\dots, v_{p+1})=0$ si $\exists i\mid v_i=v_{i+1}$. 
\begin{gather*}
d_xw(v_1,\dots, v_{p+1})=\sum_{l=1}^{p+1}(-1)^{l-1}D_xw(v_l)(v_1,\dots, \hat{v}_l,\dots, v_{p+1})=\\
\sum_{l=1}^{i-1}(-1)^{l-1}D_xw(v_l)(v_1,\dots, \hat{v}_l,\dots, v_{p+1})+\\
(-1)^{i-1}D_xw(v_i)(v_1,\dots, \hat{v}_i,\dots, v_{p+1})+(-1)^{i}D_xw(v_{i+1})(v_1,\dots, \hat{v}_{i+1},\dots, v_{p+1})+\\
\sum_{l=i+2}^{p+1}(-1)^{l-1}D_xw(v_l)(v_1,\dots, \hat{v}_l,\dots, v_{p+1})
\end{gather*}
El primer y el último sumando contienen a $v_i$ y a $v_{i+1}$, luego se anulan por se alternados. Los otros dos se anulan, porque al eliminar uno de los dos sigue estando el otro, y con el cambio de signo se cancelan.

\begin{ej}
Sea la aplicación diferenciable $x_i:U\to\R$ que consiste en proyectar sobre la $i$-ésima coordenada. $x_i\in \Omega^0(U)=C^{\infty}(U;\R)$, luego $dx_i\in\Omega^1(U)$, donde $dx_i:U\to Alt^1(\R^n)$ está definida como $x\mapsto d_x x_i$. Entonces, $d_x x_i(v)=D_x(x_i)(v)$, con $v\in\R^n$. Tengamos en cuenta que $D_x(x_i):\R^n\to Alt^0(\R^n)=\R$ es la aplicación $v\mapsto D_x(x_i)(v)$. Así que
\[
D_x(x_i)(v)=\sum_{j=1}^n\frac{\partial x_i}{\partial x_j}(x)v_j=\sum_{j=1}^n\frac{\partial x_i}{\partial x_j}(x)\varepsilon_j(v)=\left(\sum_{j=1}^n\frac{\partial x_i}{\partial x_j}(x)\varepsilon_j\right)(v)= \varepsilon_i
\]
Así que $d_xx_i=\varepsilon_i$. También escribiremos $dx_i=\varepsilon_i$ entendido como la función constante $\varepsilon_i$, ya que no se obtendría el valor concreto hasta evaluar en $x$. En general, para $f\in\Omega^0(U)$ se tiene
\[
d_xf(v)=\sum_{j=1}^n\parcial{f}{x^j}(x)v_j=\sum_{j=1}^n\parcial{f}{x^j}(x)\varepsilon_j(v)=\sum_{j=1}^n\parcial{f}{x^j}(x)dx_j(v).
\]
En otras palabras, $d_xf=\sum_{j=1}^n\parcial{f}{x^j}(x)dx_j$, o también $df=\sum_{i=1}^j\parcial{f}{x_i}dx_i$. 
\end{ej}

\begin{nota}
Haciendo el mismo desarrollo, usando la regla de Leibniz llegamos a que $d(fg)=dfg+fdg$.
\end{nota}

\begin{lemma}
Sea $w\in\Omega^p(U)$ tal que $w(x)=f(x)\varepsilon_I$ (equivalentemente $f(x)\varepsilon_{\sigma}, \sigma\in S(p,n-p)$). Entonces $dw=df\land\varepsilon_I$. 
\end{lemma}
\begin{proof}
Dado $x\in U$, $(v_1,\dots, v_{p+1})\in(\R^n)^{p+1}$. Tenemos que $D_xw(v)\in Alt^p(\R^n)$, con $v=\sum_{i=1}^nv^ie_i\in\R^n$. Entonces
\[
D_xw(v)=D_xw(\sum_{i=1}^nv^ie_i)=\sum_{i=1}^nv^iD_xw(e_i)=\sum_{i=1}^nv^i(\parcial{w_{\sigma}}{x_j}(e_i)=\sum_{i=1}^nv^i\parcial{f}{x_i}(x)\varepsilon_{\sigma}=
\]
\[
\sum_{i=1}^n\parcial{f}{x_i}(x)\varepsilon_i(v)\varepsilon_{\sigma}=(\sum_{i=1}^n\parcial{f}{x_i}\varepsilon_i)(v)\varepsilon_{\sigma}=d_xf(v)\varepsilon_{\sigma}
\]
Así pues, 
\begin{gather*}
d_xw(v_1,\dots, v_{p+1})=\sum_{l=1}^{p+1}(-1)^{l-1}D_xw(v_l)(v_1,\dots, \hat{v}_l,\dots, v_{p+1})=\\
\sum_{l=1}^{p+1}(-1)^{l-1}(d_xf(\varepsilon_l)\varepsilon_{\sigma})(v_1,\dots, \hat{v}_l,\dots, v_{p+1})=\sum_{l=1}^{p+1}(-1)^{l-1}d_xf(v_l)\varepsilon_{\sigma}(v_1,\dots, \hat{v}_l,\dots, v_{p+1})=\\
d_xf\land\varepsilon_{\sigma}(v_1,\dots, v_{p+1})
\end{gather*}
Por tanto $dw=df\land\varepsilon_{\sigma}$.
\end{proof}

\begin{lemma}
Para todo $p\geq 0$ con
\[
\Omega^p(U)\overset{d}{\longrightarrow}\Omega^{p+1}(U)\overset{d}{\longrightarrow}\Omega^{p+1}(U)
\]
se tiene que $d^2=d\circ d=0$.
\end{lemma}
\begin{proof}
Como $d$ es homomorfismo, basta comprobarlo para $w=f\varepsilon_{\sigma}$. En ese caso, 
\[dw=df\land\varepsilon_{\sigma}=(\sum_{i=1}^n\parcial{f}{x_i}\varepsilon_i)\land\varepsilon_{\sigma}=\sum_{i=1}^n\parcial{f}{x_i}\varepsilon_i\land\varepsilon_{\sigma}.
\]
\[d^2(w)=d(dw)=\sum_{i=1}^nd(\parcial{f}{x_i}(\varepsilon_i\land\varepsilon_{\sigma})=\sum_{i=1}^nd(\parcial{f}{x_i})\land(\varepsilon_i\land\varepsilon_{\sigma})=
\]
\[
\sum_{i=1}^n(\sum_{j=1}^n\frac{\partial^2 f}{\partial x_j\partial x_i}\varepsilon_j)\land\varepsilon_i\land\varepsilon_{\sigma}=\sum_{1\leq i\leq j\leq n}(\frac{\partial^2 f}{\partial x_j\partial x_i}-\frac{\partial^2 f}{\partial x_i\partial x_j})\varepsilon_j\land\varepsilon_i\land\varepsilon_{\sigma}=0
\]
pues $\varepsilon_i\land\varepsilon_j\land\varepsilon_{\sigma}=-\varepsilon_j\land\varepsilon_i\land\varepsilon_{\sigma}$.
\end{proof}

El producto exterior sobre $Alt^*(\R^n)$ induce un producto exterior sobre $\Omega^*(U)=\bigoplus_{p\geq 0}\Omega^p(U)$, donde si $w_1\in\Omega^p(U),w_2\in\Omega^q(U)$, entonces $w_1\land w_2\in \Omega^{p+q}(U9$. Basta decir que $(w_1\land w_2)(x):=w_1(x)\land w_2(x)$.  Así tenemos que
\[
\land: \Omega^p(U)\times\Omega^q(U)\to \Omega^{p+q}(U)
\]
es una aplicación bilineal verificando
\begin{enumerate}
\item $(w_1+w_2)\land w_3=w_1\land w_3+w_2\land w_3$.
\item $f\in\Omega^0(U)=C^{\infty}(U;\R)$, $w\in\Omega^p(U)$, entonces $f\land w=fw\in\Omega^p(U)$. 
\item $(fw)\land \eta =w\land f\eta=f(w\land\eta)$. 
\end{enumerate}

\begin{lemma}
Sean $w_1\in\Omega^p(U), w_2\in\Omega^q(U)$. Entonces se verifica la regla de Leibniz, es decir, 
\[
d(w_1\land w_2)=dw_1\land w_2+(-1)^pw_1\land dw_2.
\]
\end{lemma}
\begin{proof}
Por linealidad basta demostrarlo para $w_1=f\varepsilon_{\sigma}\in\Omega^p(U), w_2=g\varepsilon_{\tau}\in\Omega^q(U)$. 
\begin{gather*}
d(w_1\land w_2)=d(f\varepsilon_{\sigma}\land g\varepsilon_{tau})=d(fg(\varepsilon_{\sigma}\land\varepsilon_{\tau})=d(fg)\land (\varepsilon_{\sigma}\land\varepsilon_{\tau})=\\
(dfg+fdg)\land \varepsilon_{\sigma}\land\varepsilon_{\tau}=dfg\land\varepsilon_{\sigma}\land\varepsilon_{\tau}+fdg\land\varepsilon_{\sigma}\land\varepsilon_{\tau}=\\
df\land\varepsilon_{\sigma}\land g\land\varepsilon_{\tau}+(-1)^pf\varepsilon_{\sigma}\land \underbrace{dg\land\varepsilon_{\tau}}_{d(g\varepsilon_{\tau})}=dw_i\land w_2+(-1)^pw_1\land dw_2
\end{gather*}
\end{proof}

Por tanto, $\Omega^*(U)=\bigoplus_{p\geq 0}\Omega^p(U)$ es un álgebra graduada anticonmutativa con diferencial (DGA). A este álgebra en particular la llamamos \textbf{complejo de cocadenas de deRham}.

\begin{teorema}
Para todo $p\geq 0$, $d:\Omega^p(U)\to\Omega^{p+1}(U)$ es el único verificando 
\begin{enumerate}
\item Si $f\in\Omega^0(U)$, entonces $df=\sum_{i=1}^n\parcial{f}{x_i}\varepsilon_i$. 
\item $d^2=0$.
\item La regla de Leibniz.
\end{enumerate}
\end{teorema}
\begin{dem}
Tenemos que probar la unicidad. Supongamos que existe $d'$ verificando 1,2 y 3. Entonces, sobre las 0-formas, $d=d'$. En particular, $dx_i=\varepsilon_i=d'x_i$. Ahora, como $(d')^2=0$, $0=d'd'x_i=d'\varepsilon_i$, luego $d'\varepsilon_{\sigma}=d'(\varepsilon_{\sigma(1)}\land\dots\land\varepsilon_{\sigma(p)})=0$ reiterando la regla de Leibniz.  

Como $d$ y $d'$ son homomorfismos, basta comprobar que $d(f\varepsilon_{\sigma})=d'(f\varepsilon_{\sigma})$, de donde se ducirá que $dw=d'w$ para toda $w\in\Omega^p(U)$. 
\[
d'(f\varepsilon_{\sigma})=d'(f\land\varepsilon_{\sigma})=d'f\land\varepsilon_{\sigma}+(-1)^0f\land d'(\varepsilon_{\sigma})=d'f\land\varepsilon_{\sigma}=df\varepsilon_{\sigma}=d(f\land\varepsilon_{\sigma})
\]
\QED
\end{dem}

\begin{ej}
\begin{enumerate}
\item Sea $U\subseteq\R^3$, veamos en qué consiste $d:\Omega^1(U)\to\Omega^2(U)$. $w\in\Omega^1(U)$, $w=f_1\varepsilon_1+f_2\varepsilon_2+f_3\varepsilon_3$, entonces $dw=$ suma de cosas en $\varepsilon_i\land\varepsilon_j$, $i<j$.
\item Sea $U\subseteq\R^3$, veamos en qué consiste $d:\Omega^2(U)\to\Omega^3(U)$
\end{enumerate}
\end{ej}

Como $d^2=0$, $\Ima(d:\Omega^{p-1}(U)\to\Omega^p(U))\subseteq\ker(d:\Omega^p(U)\to\Omega^{p+1})\subseteq\Omega^p(U)$. Podemos entonces hacer el cociente, al que denotamos $H^p(U)$, que es un $\R$-e.v. llamado \textbf{$p$-ésimo e.v. de cohomología de deRham}. A los elementos $w\in\Omega^p(U)$ tales que $dw=0$ se le llaman \textbf{formas cerradas}. Y a las formas $\rho\in\Omega^p(U)$ que son imagen $\tau\mapsto d(\tau)=\rho$ se llaman \textbf{formas exactas}. Así, podemos ver $H^p$ como el cociente de $p$-formas cerradas entre $p$-formas exactas. 

Si $dw=0$ entonces define una clase de equivalencia $[w]\in H^p(U)$, también denotada $w+d(\Omega^{p-1}(U))$. Se tiene que $[w]=[w']\in H^p(U)$ si y solo si $w-w'\in d(\Omega^{p-1}(U))$. Como $w-w'=d(\tau)$, $w=w'+d(\tau)$. Veremos que el cociente es un espacio vectorial de dimensión finita a pesar de que cada espacio es de dimensión finita. 

\begin{ej}
\begin{enumerate}
\item $H^p(U)=0$ si $p<0$.
\item $H^0(U)=\ker(d:\Omega^0(U)\to\Omega^1(U))=\{f\in\Omega^0=C^{\infty}(U;\R)\mid df=0\}$. Esto es
\[
df=\sum_{i=1}^n\parcial{f}{x_i}\varepsilon_i=0
\]
o sea, que para todo $x\in U$,
\[
d_xf=\sum_{i=1}^n\parcial{f}{x_i}(x)\varepsilon_i=0\in Alt^1(\R^n)
\]
Así que $f$ es tal que $\parcial{f}{x_i}=0$ para todo $x\in U$, luego $f$ es localmente constante. 
\end{enumerate}
\end{ej}

\begin{lemma}
$H^0(U)$ es el $\R$-e.v. de aplicaciones $U\to\R$ que son constantes en cada componente arco-conexa de $U$ (de hecho en cada componente conexa). 
\end{lemma}
\begin{proof}
\end{proof}

Geométricamente, si $U=U_1\sqcup\dots\sqcup U_r$ descompuesto en componentes arcoconexas, y tomamos la función $\sum_{i=1}^nc_i\chi_{U_i}$ con $c_i\in\R$, donde $\chi_{U_i}$ es la catacterística de $U_i$. Entonces $H^0(U)=\R\times\dots\times\R$, una copia por cada $\chi_{U_i}$. Es decir, que $H^0(U)$ cuenta el número de componentes conexas de $U$.

\end{document}

