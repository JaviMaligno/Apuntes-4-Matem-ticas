\documentclass[twoside]{article}
\usepackage{../../estilo-ejercicios}
\newcommand{\media}[1]{{\overline{#1}}}
\newcommand{\muestra}[1]{{\underline{#1}}}
\newcommand{\m}[1]{{\muestra{#1}}}
\newcommand{\mX}{{\muestra{X}}}

%--------------------------------------------------------
\begin{document}

\title{Ejercicios de Análisis de Datos Multivariantes}
\author{Diego Pedraza López, Javier Aguilar Martín, Rafael González López}
\maketitle

\begin{ejercicio}{1.1}
Sea $\mX_1, \mX_2, \dots, \mX_n$ una muestra aleatoria simple de una vector $p$-dimensional $\mX \sim (\m{µ},Σ)$.
Sea $\media{\m{X}} = \frac{1}{n}\sum_{i=1}^n \m{X}_i$ y $S$ la matriz $S = [S_{jk}]$ con
\[ S_{jk} = \sum_{i=1}^n (X_{ij} - \media{X}_j)(X_{ij}-\media{X}_k), \quad j,k=1,\dots,p\]
\begin{enumerate}[(a)]
\item Demuestra que $S = \sum_{i=1}^n (\mX_i-\media{\m{X}})(\mX_i-\media{\m{X}})^t$.
\item Sea $A_{m\times p}$ y sea $\m{Y}_1,\dots,\m{Y}_n$ con $\m{Y}_i = A \m{X}_i$.

Demuestra que $\media{Y}=A \media{\mX}$ y que $S_Y = A S_X A^t$.
\item Sea $\mathbb{X}$ la matriz de datos. Demuestra que $S = \mathbb{X}^t H \mathbb{X}$, siendo $H$ simétrica e idempotente.
\item Demuestra que $E(\media{\mX}) = \m{μ}$ y $Cov(\media{\m{X}}) = \frac{1}{n} Σ$.
\item Sea $\hat{Σ} = \frac{1}{n-1}S$, demuestra que $S(\hat{Σ}) = Σ$.
\end{enumerate}
\end{ejercicio}

\newpage

\begin{ejercicio}{1.2}
Distribución normal $p$-variante, $\mX \sim N_p(\m{μ},Σ)$.
\begin{enumerate}[(a)]
\item Definición.
\item Sea $\m{Y} = Σ^{-1/2}(\mX - \m{μ})$.
\begin{enumerate}[i.]
  \item Determinar la función de densidad de $\m{Y}$.
  \item Demuestra que las componentes del vector aleatorio $\m{Y}$ son independientes e idénticamente distribuidas según una $N(0,1)$.
  \item Demuestra que $\m{Y} \sim N_p(\m{0},I_p)$.
\end{enumerate}
\item Demuestra que $E(\mX) = \m{μ}$ y $cov(\m{X}) = Σ$.
\item La función generatriz de momentos de $\m{X}$ viene dada por
\[ M(\m{t}) = E\left(e^{\m{t}'\mX}\right) = E\left(e^{\sum_{i=1}^p t_i X_i}\right) = \exp\left(\m{t}'\m{μ} + \frac{1}{2}\m{t}'Σ\m{t}\right)\]
Demuestra que
\begin{enumerate}[i.]
\item $B \mX + \m{c} ~ N(B \m{μ} + \m{c}, B Σ B^t)$.
\item Si $\mX \sim N_p(\m{μ}_1,Σ_1)$, $\m{Y} \sim N_p(\m{μ}_2,Σ_2)$ e independientes, entonces $\mX+\m{Y} \sim N_p(\m{μ}_1+\m{μ}_2, Σ_1+Σ_2)$.
\end{enumerate}
\item Sea $\mX_1,\dots,\mX_n$ una muestra aleatoria de una distribución $N_p(\m{μ},Σ)$, demuestra que $\media{\m{X}} \sim N_p(\m{μ}, \frac{1}{n}Σ)$.
\end{enumerate}
\end{ejercicio}

\newpage

\begin{ejercicio}{1.3}
Distribución de Wishart, $W \sim W_p(n,Σ)$.
\begin{enumerate}[(a)]
\item Definición.
\item Demuestra que $E(W) = nΣ$.
\item Sean $W_1 \sim W_p(n_1,Σ)$ y $W_2 \sim W_p(n_2,Σ)$, e independientes. Demuestra que $W_1 + W_2 \sim W_p(n_1+n_2,Σ)$.
\item Sea $W \sim W_p(n,Σ)$, y sea $C \in \mathcal{M}_{q\times p}$ de rango $q$. Demuestra que
\[ C W C' \sim W_q(n, CΣC') \]
\end{enumerate}
\end{ejercicio}

\newpage

\begin{ejercicio}{1.4}
Distribución $T^2$ de Hotelling, $T^2 \sim T^2_{p,n}$.
\begin{enumerate}[(a)]
\item Definición.
\item Sea $\mX \sim N_p(\m{μ},Σ)$ y $W \sim W_p(n,Σ)$ independientes. Demuestra que:
\[ n(\mX-\m{μ})' W^{-1} (\mX-\m{μ}) \sim T^2_{p,n} \]
\end{enumerate}
\end{ejercicio}

\newpage

\begin{ejercicio}{1.5}
Sea $\mX_1,\dots,\mX_n$ una muestra aleatoria de una distribución $N_p(\m{μ},Σ)$.
\begin{enumerate}[(a)]
\item Sabiendo que $\media{\mX}$ y $S$ son independientes y que $S \sim W_p(n-1,Σ)$, demuestra que
\[ n(n-1)(\media{\mX}-\m{μ})' S^{-1} (\mX-\m{μ}) \sim T^2_{p,n-1}\]
\item Sea $A$ una matriz $m\times p$ ($m≤p$), de rang $m$ y $\m{d}$ un vector $m$-dimensional.
El estadístico del test de razón de verosimilitudes para el contraste:
\[ H_0 \colon A\m{μ} = \m{d} \quad vs \quad H_1 \colon A\m{μ} \neq \m{d} \]
viene dado por:
\[ T^2 = (n-1)n (A\media{\mX})^t (ASA^t)^{-1} (A \media{\mX}-\m{d}) \]
Demuestra que, bajo $H_0$:
\[ T^2 \sim T^2_{m,n-1} \]
\end{enumerate}
\end{ejercicio}

\newpage

\[ A = \begin{pmatrix} 1 & 0 & \dots & 0& -1 & 0 & \dots & 0\\
 0 & 1 & \dots & 0 & 0 & -1 & \dots & 0\\
 \vdots\\
  0 & 0 & \dots & 1 & 0 & 0 & \dots & -1\\\end{pmatrix} \]

\end{document}
