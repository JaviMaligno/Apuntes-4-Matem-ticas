\documentclass[MIOP.tex]{subfiles}
\usepackage{mathtools}
%\usepackage{sagetex}
\begin{document}

\chapter{Programación no lineal.}

\section{Introducción.}

El objetivo de la programación no lineal es resolver problemas de la siguiente naturaleza: dada $f:\R^n\to\R$, encontrar $x^*$ tal que $f(x^*)=\min_{x\in\R^n}f(x)$. Puede que el problema no esté bien definido, es decir, que no exista tal mínimo, por ejemplo $f(x)=-\frac{1}{x}$. Las condiciones suficientes para la existencia de solución a este problema son:
\begin{enumerate}
\item $f$ es continua.
\item $f$ es coerciva, i.e., $\lim_{||x||\to\infty} f(x)=+\infty$. Gracias a esto, $\exists M\mid ||x||\leq M\Rightarrow f(x)\leq f(y)\ \forall ||y||>M\Rightarrow \min_{x\in\R^n}f(x)=\min_{||x||\leq M}f(x)$.
\end{enumerate}
Supongamos que $f$ es continuamente diferenciable y supongamos que $x^*$ es un mínimo local de $f$, es decir, $\exists E(x^*)$ tal que $f(x^*)\leq f(x)\ \forall x\in E(x^*)$. Podemos hallar el desarrollo en serie de Taylor en el punto $x^*$, dados $d\in\R^n,\alpha\in\R$
$$f(x^*+\alpha d)=f(x^*)+\underbrace{\alpha d'}_{x^*+\alpha d-x^*}\nabla f(x^*)+\mathcal{O}(||\alpha d||)$$
Tomando $\alpha>0$ tenemos
$$f(x^*+\alpha d)-f(x^*)\approx \alpha d'\nabla f(x^*)\geq 0\Rightarrow d'\nabla f(x^*)\geq 0.$$
Esto se cumple para toda dirección, en particular para $-d$, pero si $-d\nabla f(x^*)=0$, entonces $\nabla f(x^*)=0$. 

Si desarrollamos hasta segundo orden
$$f(x^*+\alpha d)=f(x^*)+\alpha d'\nabla f(x^*)+\frac{\alpha^2}{2}d'\nabla^2 f(x^*)d+\mathcal{O}(||\alpha d||^2)$$
análogamente deduciríamos, aplicando que $\nabla f(x^*)=0$, 
$$f(x^*+\alpha d)-f(x^*)\approx \frac{\alpha^2}{2}d'\nabla^2 f(x^*)d\geq 0\ \forall d.$$
Esto significa que la matriz $\nabla^2 f(x^*)$ es semidefinida positiva.

Vamos a probar rigurosamente estos resultados en el siguiente teorema.

\begin{teorema}
Sea $x^*$ mínimo local de $f$ continuamente diferenciable en un entorno abierto $S$ de $x^*$. Entonces $\nabla f(x^*)=0$. Si además $f$ es de clase $\mathcal{C}^2(S)$, entonces $\nabla^2 f(x^*)$ es semidefinida positiva.
\end{teorema}
\begin{dem}
 Consideremos $d \in \R^n$ arbitraria con $||d||=1$. Definimos:
\begin{align*}
g &: \R \to \R\\
g(α) &= f(x^* + α d)
\end{align*}
Como $x^*$ es un mínimo local, si $α > 0$ es suficiente pequeño: $0 ≤ f(x^*+αd)-f(x^*)$.
\[ 0 ≤ \frac{f(x^*+αd)-f(x^*)}{α} \Rightarrow 0 ≤ \lim_{α \to 0} \frac{f(x^*+αd)-f(x^*)}{α} = g'(0) \]
Entonces $0 ≤ g'(0) = d'\nabla f (x^*+αd) |_{α = 0} = d'\nabla f(x^*)$. 
Como $||e_i|| = ||-e_i|| = 1$, $\nabla f(x^*)'e_i ≥ 0$ y $\nabla f(x^*)'(-e_i) ≥ 0$, luego $\nabla f(x^*) = 0$. Ahora, si $f \in \mathcal{C}^2$. Entonces:
\begin{align*} 0 ≤ f(x^* + α d)-f(x^*) & = \nabla f(x^*)(αd) + \frac{1}{2} (αd)' \nabla^2 f(x^*)(αd) + O(||αd||^2) \\
 & = \frac{α^2}{2}d'\nabla^2f(x^*)d + O(α^2)
\end{align*}
Dividiendo por $α^2$ y pasando al límite:
\[ 0 ≤ \frac{1}{2} d' \nabla^2 f(x^*) d \]
Luego $\nabla^2 f(x^*)$ es semidefinida positiva. $\QED$
\end{dem}

\begin{teorema}[C. S.] Sea $f\in \mathcal{C}^2(S)$, S abierto. Supongamos que $x^*\in S$. Supongamos que verifica:
\begin{enumerate}
\item $\nabla f(x^*)=0$
\item $\nabla^2 f(x^*)$ definida positiva.
\end{enumerate}
Entonces $\exists \gamma>0$, $\delta>0$ tal que 
\[
f(x)\geq f(x^*)+\frac{\gamma}{2}||x-x^*||^2 \qquad \forall x\in S,\; ||x-x^*||<\delta
\]
\end{teorema}
\begin{dem}
Por las propiedades de las matrices definidas positivas, sabemos que $\exists \lambda>0$ -el menor autovalor de la matriz- tal que $\forall d\in \R^n$, $d'\nabla^2 f(x^*) d\geq \lambda ||d||^2$. Sea $d\in \R^n$ tal que $x^*+d \in S$, entonces:
\begin{gather*}
f(x^*+d)=f(x^*)+\nabla f(x^*)'d +\frac{1}{2}d'\nabla^2 f(x^*)d+O(||d||^2) \\
f(x^*+d)-f(x^*) =  \frac{1}{2}d'\nabla^2 f(x^*)d+O(||d||^2) \geq  \frac{\lambda}{2}||d||^2 + O(||d||^2) = \frac{||d^2||}{2}\left(\lambda+\frac{O(||d||^2)}{||d||^2}\right)
\end{gather*}
Sabemos que $\forall \varepsilon>0$ ($\varepsilon < \lambda$) $\exists \delta >0$ tal que si $||d||<\delta$ entonces $\left|\dfrac{O(||d||^2)}{||d||^2}\right|<\varepsilon$, por tanto, si $||d||<\delta$ entonces
\[
f(x^*+d)-f(x^*)\geq  \frac{||d||^2}{2}\left(\lambda+\frac{O(||d||^2)}{||d||^2}\right) \geq  \frac{||d||^2}{2}\left(\lambda-\varepsilon\right) =  \frac{\gamma}{2}||d||^2 \]

Basta tomar $d=x-x^*$ $\QED$ 
\end{dem}

\begin{defi}
Diremos que $x^*$ es un \textbf{punto estacionario} de $f$ si $\nabla f(x^*)=0$. 
\end{defi}

\section{Algoritmos de tipo gradiente}
Sea $d^k \in\R^n$ la dirección desplazamiento y $a^k \in \R$ la longitud de paso, nuestros métodos serán de la forma:
\[
\begin{cases}
\text{Dado $x^0\in \R^n$}\\
x^{k+1} = x^k - \alpha^k d^k
\end{cases}
\]
con $d^k\mid {d^k}'\nabla f(x^k)<0, \alpha^k>0\ \forall k$. En particular, si $d^k=-\nabla f(x)$ es la dirección de máximo decrecimiento local de $f$ en $x$ obtenemos el llamado \textbf{Método de máximo descenso}:
\[
\begin{cases}
\text{Dado $x^0\in \R^n$}\\
x^{k+1} = x^k - \alpha^k \nabla f(x^k)
\end{cases}
\]
Para este caso particular se tiene que:
\[
f(x^{k+1})=f(x^k)+\nabla f(x^k)(x^{k+1}-x^k) + O(||x^{k+1}-x^k||) \approx f(x^k)-\nabla f(x^k)\alpha^k d^k
\]
Con esto conseguimos que $f(x^{k+1})\leq f(x^k)$ (podemos conseguirlo con cualquier dirección $d^k$ de las anteriores). Luego la condición de parada será $x^{k+1}=x^k$, es decir, $\nabla f(x^k)=0$. 


\subsection{Elementos de este método}
\begin{enumerate}
\item $x^0$ punto inicial.
\item Dirección de desplazamiento
\begin{itemize}
\item $d^k = -\nabla f(x^k)$ (Método de máximo descenso).
\item $d^k = -D^k \nabla f(x^k)$ con $D^k$ definida positiva. Esto permite hacer una cantidad infinita de iteraciones sin que el método se atasque.
\begin{itemize}
\item Tomar, si es definida positiva, $D^k = (\nabla^2 f(x^k))^{-1}$. En este caso obtenemos el método de Newton.
\item Para $D^k=I$ tenemos el método de máximo ascenso.
\end{itemize}
\end{itemize}
\item La longitud de paso $\alpha^k$.
\begin{itemize}
\item Elementos de una serie divergente $\sum \alpha_k$ tal que $\alpha_k \rightarrow 0$. A este método se lo conoce como \textbf{método de la serie divergente} Tiene sentido pues:
\begin{gather*}
x^{m+1} = x^m - \alpha^m \nabla f(x^{m})\\
 x^{m+2} = x^{m+1} - \alpha^{m+1} \nabla f(x^{m+1}) =  x^m - \alpha^m \nabla f(x^{m}) -\alpha^{m+1} \nabla f(x^{m+1})
\end{gather*}
Si $m$ es lo suficientemente grande entonces $\forall n>m$, $x^n \simeq x^m \simeq x^*$ y
\[
x^* \simeq x^* - \sum^{n-1}_{k=m} \alpha^k \nabla f(x^*) \Rightarrow 0 \simeq \nabla f(x^*)\sum_{k=m}^\infty \alpha^k
\]
Como la serie diverge, concluimos que $\nabla f(x^*)=0$.
\item \textbf{Método o regla de minimización}: tomar una dirección $d^k$ y $\alpha^k$ tal que $\alpha^k$ minimiza $f(x^k+\alpha d^k)$ para $\alpha>0$ (función de una variable real).
\item \textbf{Regla de Armijo}: elegimos $s,\beta,\sigma\in (0,1)$. Entonces definimos $\alpha^k=s\beta^{m_k}$, siendo $m_k$ el menor entero que verifica
$$f(x^k)-f(x^{k+1})=-\sigma s\beta^{m_k}\nabla f(x^k)d^k.$$
\end{itemize}
\end{enumerate}

\begin{ej}
$f(x_1,x_2)=(x_1-3)^2+(x_2-2)^2$. Fijamos $x^0=\begin{pmatrix}
1\\
1
\end{pmatrix}$. Entonces $x^1=x^0-\alpha^0\nabla f(x^0)$, donde $\nabla f(x_1,x_2)=\begin{pmatrix}
2(x_1-3)\\
2(x_2-2)
\end{pmatrix}$, por lo que $x^1=\begin{pmatrix}
1+\alpha^0 4\\
1+\alpha^0 2
\end{pmatrix}$. Utilizamos la regla de minimización para determinar $\alpha^0$ con la dirección que nos marca $x^1$. Es decir, buscamos
$$\min_{\alpha>0}f(1+4\alpha,1+2\alpha)=(-2+4\alpha)^2+(-1+2\alpha)^2$$
que se obtiene en $\alpha=\frac{1}{2}$, por lo que $x^1=\begin{pmatrix}
3\\
2
\end{pmatrix}$. De la misma forma calcularíamos $x^2$, pero resulta que $\nabla f(x^1)=0$, por lo que $x^2=x^1$ y hemos terminado. Era precedible pues la función es siempre mayor o igual que cero y en el $(3,2)$ se anula.
\end{ej}

\begin{defi}
La sucesión $\{d^k\}$ se denomina de \textbf{tipo gradiente} si verifica que cualquier subsucesión que converge a un punto estacionario cumple: 
\begin{enumerate}
\item La subsucesión está acotada, i.e., $\exists M>0\mid ||d^k||<M\ \forall k$. 
\item $\lim\sup_{k\in K}\nabla f(x^k)'d^k<0$. \label{gradiente}
\end{enumerate}
\end{defi}

\begin{teorema}
Sea $\{x^k\}$ una sucesión generada con el algoritmo $x^{k+1}=x^k+\alpha^kd^k$, siendo $\{d^k\}$ una sucesión de direcciones de tipo gradiente y $\{\alpha^k\}$ generada mediante la regla de Armijo. Entonces todo punto de acumulación de $\{x^n\}$ es estacionario.
\end{teorema}
\begin{dem}
Supongamos que $\{x^n\}$ tiene un punto de acumulación $\overline{x}$ que no es estacionario. Nos restringimos a la subsucesión que converge a $\overline{x}$, que denominamos igual. Dado que $x^n\to \overline{x}$ y $f$ es continuamente diferenciable, entonces $f(x^n)\to f(\overline{x})$. Por tanto $f(x^n)-f(x^{n+1})\to f(\overline{x})-f(\overline{x})=0$. 

Por elección de los $\alpha^k$ según Armijo, 
\begin{equation}\label{armijo}
f(x^k)-f(x^k+s\beta^{m_k}d^k)\geq -\sigma\alpha^k\nabla f(x^k)'d^k.
\end{equation}
 Como $m_k$ es el menor entero para el que se verifica esa desigualdad, entonces 
$$f(x^k)-f(x^k+\underbrace{s\beta^{m_k-1}}_{\frac{\alpha^k}{\beta}}d^k)<\sigma\frac{\alpha^k}{\beta}\nabla f(x^k)'d^k.$$ 
Denotamos $\rho^k=\frac{d^k}{||d^k||},\overline{\alpha}^k=\frac{\alpha^k||d||^k}{\beta}$, de modo que la desigualdad se convierte en 
$$ f(x^k)-f(x^k+\overline{\alpha}^k\rho^k)< -\sigma\overline{\alpha}^k\nabla f(x^k)'\rho^k.$$
Utilizando ahora el teorema del valor medio, es decir, $f(y)=f(x)+\nabla f(x)(y-x)$ para $z\in[x,y]$, deducimos
$$-\nabla f(x^k+\tilde{\alpha}^k\rho^k)\overline{\alpha}^k\rho^k <-\sigma\overline{\alpha}^k\nabla f(x^k)'\rho^k\quad \tilde{\alpha}^k\in[0,\overline{\alpha}^k]$$
Podemos simplificar eliminando los $\overline{\alpha}^k$
\begin{equation}\label{simply}
\nabla f(x^k+\tilde{\alpha}^k\rho^k)\rho^k <-\sigma\nabla f(x^k)'\rho^k\quad \tilde{\alpha}^k\in[0,\overline{\alpha}^k]
\end{equation}
Observemos que $\alpha^k\to 0$. Según \ref{armijo}
$f(x^k)-f(\underbrace{x^k+\alpha^kd^k}_{x^{k+1}})\geq -\sigma\alpha^k\nabla f(x^k)'d^k\ \forall k$. Como la diferencia de la izquierda tiende a 0 cuando $k$ tiende a infinito y $-\sigma\nabla f(x^k)'d^k>0$, necesariamene $\alpha^k$ tiende a 0. Como $||d^k||$ está acotada, tenemos que también $\overline{\alpha}^k\to 0$. La sucesión $\{\rho^k\}$ está contenida en un compacto (la bola unidad), así que tiene un a subsucesión convergente que denominaremos de la misma forma, así que denotamos $\rho^k\to\overline{\rho}$. 

Volvemos a \ref{simply} y tomamos límite. Entonces
$$-\nabla f(\overline{x}+0\overline{\rho})'\overline{\rho}<\sigma\nabla f(\overline{x})'\overline{\rho}$$
que podemos reescribirlo como
$$(1-\sigma)\nabla f(\overline{x})'\overline{rho}>0$$
por lo que $\nabla f(\overline{x})'\overline{\rho}>0$. Sin embargo, esto contradice punto \ref{gradiente} de la definición anterior. 
$\QED$
\end{dem}

\begin{nota}
Si en lugar de la regla de Armijo se usa la de minimización, el resultado sigue siendo válido. Si denotamos $x^{k+1}_A$ y $x^{k+1}_m$ a los sucesores construido con cada una de las reglas, entonces se verifica $f(x^{k+1}_A)\geq f(x^{k+1}_m)$, por lo que la desigualdad \ref{armijo} sigue siendo válida.
\end{nota}

\begin{teorema}[de captura]
Sea $f\in\mathcal{C}^1$ y $\{x^k\}$ tal que $x^{k+1}=x^k+\alpha^k d^k$ verificando que $f(x^k)>f(x^{k+1})\ \forall k$ y tal que todo punto de acumulación es estacionario. Supongamos que existen $s>0,c>0$ de forma que
$$\alpha^k\leq s, ||d^k||\leq c||\nabla f(x^k)||\ \forall k.$$
Sea $x^*$ mínimo local de $f$ que es el único punto estacionario en un entorno de $x^*$. Entonces existe $S\ni x^*$ tal que si $x^{\overline{k}}\in S$ para algún $\overline{k}$, $x^k\in S\ \forall k>\overline{k}$ y $x^k\to x^*$. Además, dado $\varepsilon>0$, $S$ se puede elegir para que $||x-x^*||<\varepsilon \ \forall x\in S$.
\end{teorema}
\begin{dem}
Elegimos $\rho>0$ tal que $\forall x\neq x^*\mid ||x-x^*||<\rho$, entonces $f(x)>f(x^*)$. Definismo $\phi
(t)=\min_{0\leq t\leq ||x-x^*||} (f(x)-f(x^*))$. $\phi$ es no decreciente, porque cuando $t$ disminuye, la corona circular se hace más gruesa hacia dentro, por lo que hay más puntos donde encontrar el mínimo, y si $t$ aumenta, la corona se hace más fina por lo que hay menos puntos donde encontrar el mínimo.

Utilizamos la continuidad de de la norma y $\nabla f$ para decir que $\forall \varepsilon>0\ \exists r>0\mid ||x-x^*||<r\Rightarrow |g(x)-g(x^*)|<\varepsilon$, donde $g(x)=||x-x^*||+sc||\nabla f(x)||$. Se tiene que $g(x^*)=0$. Luego
\begin{equation}\label{estrella}
||x-x^*||+sc||\nabla f(x)||<\varepsilon 
\end{equation}
Entonces definimos $S:=\{x\mid ||x-x^*||<\varepsilon, f(x)< f(x^*)+\phi(r)\}$. Supongamos que $x^k\in S$, entonces para $t=||x^*-x^k||$, $\phi(t)\leq f(x^k)-f(x^*)<\phi(r)$. Como $\phi$ es monótona, $||x^k-x^*||<r$, por lo que podemos aplicarle \ref{estrella} a $x^k$. Veamos que $x^{k+1}\in S$. Tenemos que probar dos desigualdades.
\begin{itemize}
\item $||x^{k+1}-x^k||=||x^k+\alpha^kd^k-x^*||=||x^k-x^*+\alpha^kd^k||\leq ||x^k-x^*||+\alpha^k||d^k||\leq\\ ||x^k-x^*||+sc||\nabla f(x^k)||<\varepsilon$
\item $f(x^{k+1})<f(x^k)<f(x^*)$
\end{itemize}
Por lo que $x^{k+1}\in S$. Además $S$ está contenido en un compacto (una bola cerrada de radio $\varepsilon$), por lo que toda sucesión contiene una subsucesión convergente, esto es, $\{x^l\}_{l>k}$ contiene una subsucesión convergente. Y como $x^*$ es el único punto estacionario, la sucesión debe converger hacia dicho punto $x^*$. $\QED$
\end{dem}

\subsection{Tasa de convergencia del método de descenso máximo para funciones cuadráticas}
Supongamos que $Q\in\R^{n\times n}$ simétrica definida positica. Sean $m,M$ los autovalores mínimo y máximo de $Q$, entonces $\forall y\neq 0, y\in\R^n$ se tiene la \emph{desigualdad de Kantorovich}
$$\frac{(y'y)^2}{(y'Qy)(y'Q^{-1}y)}\geq\frac{4Mm}{(M+m)^2}$$

\begin{teorema}
Sea $f(x)=\frac{1}{2}x'Qx, Q\in\R^{n\times n}$ simétrica y definida positiva. El algoritmo $x^{k+1}=x^k-\alpha^k\nabla f(x^k)$ con $\alpha^k$ mediante la regla de minimización verifica
$$f(x^{k+1})\leq \left(\frac{M-m}{M+m}\right)^2f(x^k).$$
\end{teorema}
\begin{dem}
Por la definición de $f$, $\nabla f(x)=Qx$. En la iteración $k$, $f(x^k)=\frac{1}{2}x^{k'}Qx^k$, luego $\nabla f(x^k)=Qx^k:=g^k$. Podemos escribir $f(x^k)=\frac{1}{2}x^{k'}QQ^{-1}Qx^k=\frac{1}{2}g^{k'}Q^{-1}g^k$. 

$\alpha^k$ mediante minimización, $g(\alpha)=f(x^k-\alpha\nabla f(x^k)), \min_{\alpha>0}g(\alpha)$. 
\begin{gather*}
g'(\alpha)=\frac{dg(\alpha)}{d\alpha}=-\nabla f(x^k)'\nabla f(x^k-\nabla f(x^k))=0\\
=-g^{k'}Q[x^k-\alpha g^k]=g^{k'}Qx^k-\alpha g^{k'}Qg^k=0\\
\alpha=\frac{g^{k'}g^k}{g^{k'}Qg^k}\Rightarrow \alpha^k=\frac{g^{k'}g^k}{g^{k'}Qg^k}
\end{gather*}
\begin{gather*}
f(x^{k+1})=\frac{1}{2}[x^k-\frac{g^{k'}g^k}{g^{k'}Qg^k}g^k]'Q[x^k-\frac{g^{k'}g^k}{g^{k'}Qg^k}g^k]=\frac{1}{2}[x^{k'}Qx^k-\frac{(g^{k'}g^k)^2}{g^{k'}Qg^k}]=\\
\frac{1}{2}x^{k'}Qx^k-\frac{1}{2}\frac{(g^{k'}g^k)^2}{g^{k'}Qg^k}=\frac{1}{2}g^{k'}Q^{-1}g^k-\frac{1}{2}\frac{(g^{k'}g^k)^2}{g^{k'}Qg^k}=\\
\frac{1}{2}g^{k'}Q^{-1}g^k[1-\frac{1}{2}\frac{(g^{k'}g^k)^2}{(g^{k'}Qg^k)(g^{k'}Q^{-1}g^k)}\leq\frac{1}{2}g^{k'}Q^{-1}g^k[1-\frac{4Mm}{(M+m)^2}]=\\
\frac{1}{2}g^{k'}Q^{-1}g^k\left(\frac{M-m}{M+m}\right)^2=f(x^k)\left(\frac{M-m}{M+m}\right)^2
\end{gather*}
$\QED$
\end{dem}

\subsection{Método de Newton generalizado}
Si tenemos $g:\R^{n}\times\R^{ n}\to \R^n$, $g=(g_1,\dotsc,g_n)$ con $g_i : \R^n \to \R$. Tratamos de resolver $g(x)=0$. Si $\exists F\mid \nabla F = g$ entonces buscamos $\nabla F =0$, es decir, buscamos:
\[
x^{k+1} =x^k - \alpha^k (\nabla^2 F(x^k))^{-1}\nabla F(x^k)
\]
Si $g$ no tiene primitiva podemos reemplazar los términos 
\[
x^{k+1}=x^k-\alpha^k(\nabla g(x^k)')^{-1} g(x^k)
\]
Se tomará $\alpha^k =1$ $\forall k$ (si $\nabla g(x^k)$ es definida positiva), lo cual da lugar al \emph{método de Newton en forma pura}.

\begin{teorema}
Sea $g:\R^n\to\R^n$ y $x^*$ tal que $g(x^*)=0$. Sea $S_\delta=\{x\in\R^n:||x-x^*||\leq\delta\}$. Supongamos que $g\in\mathcal{C}^1(S_\delta)$ y $\nabla g(x^*)$ es invertible. Entonces
\begin{itemize}
\item[a)] Existe $\delta>0$ tal que si $x^0\in\S_\delta$, la sucesión $x^k$ está bien definida y converge a $x^*$. Además, la convergencia es súper lineal, es decir,
$$\lim_{k\to\infty}\frac{||x^{k+1}-x^*||}{||x^k-x^*||}=0.$$
\item[b)] Si para algún $L>0,M>0$, $x,y\in S_\delta\Rightarrow ||\nabla g(x)-\nabla g(y)||\leq L||x-y||$ (si $\nabla g$ es lipschitziana), entonces si $x^0\in S_\delta$ se verifica $||x^{k+1}-x^*||\leq LM/2||x^k-x^*||^2\forall k$ (tiene convergencia cuadrática).
\end{itemize}
\end{teorema}
\begin{dem}
$\nabla g(x^*)$ es invertible si y solo si $\det(\nabla g(x^*))\neq 0\Rightarrow\det(\nabla g(x))\neq 0$ en $S_\delta$ para algún $\delta>0$. Por tanto $\exists M>0$ tal que $||\nabla g(x)^{-1}||<M\ \forall x\in S_\delta$. 
\begin{itemize}
\item[a)] Supongamos que $x^k\in S_\delta$ y consideremos $x^{k+1}$. Entonces
$$||x^{k+1}-x^k||=||x^k-(\nabla g(x^k)')^{-1}g(x^k)-x^*||=||(\nabla g(x^k)')^{-1}[-g(x^k)+\nabla g(x^k)'(x^k-x^*)||.$$
Usamos la fórmula del valor intermedio del cálculo integral
$$g(x^k)=g(x^*)+\int_0^1\nabla g(x^*+t(x^k-x^*))'dt\cdot(x^k-x^*)$$
que aplicada a la ecuación anterior, como $g(x^*)=0$  da lugar a
\begin{gather*}
||(\nabla g(x^k)')^{-1}[-g(x^*)-\int_0^1\nabla g(x^*+t(x^k-x^*))'dt\cdot(x^k-x^*)+\nabla g(x^k)'(x^k-x^*)]||=\\
||(\nabla g(x^k)')^{-1}\int_0^1(\nabla g(x^*)'-\nabla g(x^*+t(x^k-x^*))')dt\cdot(x^k-x^*)]||\leq\\
\end{gather*}
Aplicando desigualdades de produtos e integrales matriciales
\begin{equation}\label{estrella}
\leq||(\nabla g(x^k)')^{-1}||\int_0^1||(\nabla g(x^*)'-\nabla g(x^*+t(x^k-x^*))')||dt||x^k-x^*||
\end{equation}
Por continuidad de $\nabla g, \forall\varepsilon/M>0\ \exists\delta'\leq\delta$ tal que si $||x^k-x^*||<\delta'\Rightarrow ||\nabla g(x^*)-\nabla g(x^*+t(x^k-x^*))')||<\varepsilon/M$. Por tanto, el término anterior queda mayorado por
$$M\int_0^1\varepsilon/M dt ||x^k-x^*||=\varepsilon ||x^k-x^*||.$$
En definitiva, $\forall\varepsilon>0, ||x^{k+1}-x^*||\leq\varepsilon||x^k-x^*||$, lo que significa que $$\lim_{k\to\infty}\frac{||x^{k+1}-x^*||}{||x^k-x^*||}=0.$$
\item[b)] En \ref{estrella} aplicamos que $\nabla g$ es lipschitziana, entonces ese término está acotado por
$$||(\nabla g(x^k)')^{-1}||\int_0^1||x^*-x^*-t(x^l-x^*)||dt||x^k-x^*||\leq ML\int_0^1 t||x^k-x^*||^2=ML/2||x^k-x^*||^2$$
lo que prueba que $ ||x^{k+1}-x^*||=ML/2||x^k-x^*||^2$. $\QED$
\end{itemize}
\end{dem}
\subsection{Método Quasi-Newton}
En Newton, $d^k=-(\nabla^2 f(x^k))^{-1})\nabla f(x^k)$, que es equivalente a encontrar la solución del sistema $\nabla^2 f(x^k))d^k=-\nabla g(x^k)$.  Podríamos tener que $\nabla^2 f(x)$ no sea definido positivo o que no sea invertible. Entonces consideramos el sistema $(\nabla^2 f(x^k)-\Delta^k)d^k=-\nabla g(x^k)$, con $\Delta^k$ diagonal con entradas positivas de modo que al sumar cada una con el autovalor correspondiente de $\nabla^2 f(x^k)$ salga positivo. Entonces la matriz resultante sí es definida positiva, por lo que admite una descomposición de Cholesky con una matriz $L^k$ triangular
$$\nabla^2 f(x^k)+\Delta^k=L^{k'}L^k\Rightarrow L^{k'}\underbrace{L^kd^k}_{y^k}=-\nabla f(x^k)\equiv L^{k'}y^k=-\nabla f(x^k).$$
Por lo que $y^k=-(L^{k'})^{-1}\nabla f(x^k)$, de donde $d^k=(L^k)^{-1}y^k$.

\section{Optimización con restricciones convexas}
Supongamos que existe $S\subset\R^n$ convexo cerrado y $f:\R^n\to\R, f\in\mathcal{C}^1(S)$. Se considera el problema $(P)\min_{x\in S} f(x)$. En el interior de $S$ sigue siendo condición necesaria que $\nabla f(x)=0$, pero en la frontera no podemos hacer esto, porque no podemos considerar las direcciones opuestas. Sí que podemos pedir que $\nabla f(x^*)(x-x^*)\geq 0\ \forall x\in S$. 
\begin{teorema}
Si $x^*$ mínimo local de $(P)$, entonces  $\nabla f(x^*)(x-x^*)\geq 0\ \forall x\in S$.
\end{teorema}
\begin{dem}
Sea $1>\varepsilon>0$ suficientemente pequeño. Por el teorema del valor medio podemos expresar para algún $s\in[0,1]$
$$f(x^*+\varepsilon(x-x^*))=f(x^*)+\nabla f(x^*+s\varepsilon (x-x^*))'[x^*+\varepsilon(x-x^*)-x^*]=f(x^*)+\nabla f(x^*+s\varepsilon (x-x^*))'\varepsilon(x-x^*)$$
Supongamos que la condición del teorema no es cierta. Entonces $\exists x'\mid \nabla f(x^*)(x-x^*)<0$. Por continuidad se tendrá la desigualdad en un entorno de $x'$. Para ese $x'$ utilizamos el desarrollo anterior. 
$$f(x^*+\varepsilon(x'-x^*))=f(x^*)+\nabla \varepsilon \underbrace{f(x^*+s\varepsilon (x'-x^*))'(x'-x^*)}_{<0}$$
Entonces $f(x^*+\varepsilon(x'-x^*))< f(x^*)$, lo cual contradice que $x^*$ sea mínimo local. $\QED$
\end{dem}


\end{document}
